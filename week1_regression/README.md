# ğŸ“˜ Week 1 - RÃ©gression

Nous prÃ©sentons les **concepts thÃ©oriques de la rÃ©gression** Ã©tudiÃ©s en Data Science.  

---

## ğŸŒ± Quâ€™est-ce que la rÃ©gression ?  

La **rÃ©gression** est une mÃ©thode statistique et de machine learning qui permet de **modÃ©liser** et **prÃ©dire** une variable cible (souvent notÃ©e **y**) en fonction dâ€™une ou plusieurs variables explicatives (**features**, notÃ©es \(x_1, x_2, â€¦, x_n\)).  

ğŸ‘‰ En clair : câ€™est une faÃ§on de trouver la **relation** entre des donnÃ©es.  

**Exemple :** prÃ©dire la note dâ€™un Ã©tudiant (y) en fonction du nombre dâ€™heures dâ€™Ã©tude (x).  

---

## ğŸ“˜ 1. RÃ©gression LinÃ©aire  

- **Objectif :** prÃ©dire une **valeur continue** (salaire, prix, tempÃ©rature).  
- **ModÃ¨le mathÃ©matique :**  

\[
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_n x_n + \epsilon
\]

- \(y\) = valeur Ã  prÃ©dire  
- \(x_i\) = variables explicatives  
- \(\beta_i\) = coefficients (impact de chaque variable)  
- \(\epsilon\) = erreur  

**Exemple :** prÃ©dire le **prix dâ€™une maison** en fonction de sa surface et du nombre de chambres.  

---

## ğŸ“˜ 2. RÃ©gression Logistique  

- **Objectif :** prÃ©dire une **catÃ©gorie** (oui/non, malade/pas malade, spam/non-spam).  
- Utilise la **fonction sigmoÃ¯de** pour transformer la sortie en probabilitÃ© entre 0 et 1 :  

\[
P(y=1|x) = \frac{1}{1+e^{-(\beta_0 + \beta_1 x)}}
\]

- Si la probabilitÃ© > 0.5 â†’ classe 1  
- Sinon â†’ classe 0  

**Exemple :** prÃ©dire si un client va **rÃ©silier un abonnement** (1 = oui, 0 = non).  

---

## ğŸ“˜ 3. RÃ©gularisation  

Lorsque le modÃ¨le a beaucoup de variables, il peut trop bien mÃ©moriser les donnÃ©es (**overfitting**).  
La rÃ©gularisation ajoute une **pÃ©nalisation** pour contrÃ´ler les coefficients.  

- **Ridge (L2)** : rÃ©duit les grands coefficients (jamais Ã  0).  
- **Lasso (L1)** : pousse certains coefficients Ã  0 â†’ sÃ©lectionne automatiquement les variables utiles.  
- **ElasticNet** : combinaison de L1 et L2.  

**Exemple :** prÃ©dire le salaire avec 50 variables (Ã¢ge, ville, diplÃ´me, â€¦).  
Le Lasso peut ignorer les variables inutiles en mettant leurs coefficients Ã  0.  

---

## âœ… RÃ©sumÃ©  

- **RÃ©gression linÃ©aire** â†’ prÃ©dire un **nombre** (valeur continue).  
- **RÃ©gression logistique** â†’ prÃ©dire une **classe** (catÃ©gorie).  
- **RÃ©gularisation** â†’ Ã©viter le surapprentissage et simplifier le modÃ¨le.  

---

âœï¸ *Cours - Week 1 du parcours Data Science.*
